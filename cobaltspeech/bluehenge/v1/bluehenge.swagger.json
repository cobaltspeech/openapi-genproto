{
  "swagger": "2.0",
  "info": {
    "title": "cobaltspeech/bluehenge/v1/bluehenge.proto",
    "version": "version not set"
  },
  "tags": [
    {
      "name": "BluehengeService"
    }
  ],
  "consumes": [
    "application/json"
  ],
  "produces": [
    "application/json"
  ],
  "paths": {},
  "definitions": {
    "bluehengev1CreateSessionResponse": {
      "type": "object",
      "properties": {
        "diathekeCreateSessionResponse": {
          "$ref": "#/definitions/diathekev3CreateSessionResponse"
        }
      },
      "description": "The top-level message sent by the server for the `CreateSession` method."
    },
    "bluehengev1DeleteSessionResponse": {
      "type": "object",
      "properties": {
        "diathekeDeleteSessionResponse": {
          "$ref": "#/definitions/diathekev3DeleteSessionResponse"
        }
      },
      "description": "The top-level message sent by the server for the `DeleteSession` method."
    },
    "bluehengev1ListModelsResponse": {
      "type": "object",
      "properties": {
        "diathekeListModelsResponse": {
          "$ref": "#/definitions/diathekev3ListModelsResponse"
        }
      },
      "description": "A list of models available on the Bluehenge server."
    },
    "bluehengev1StreamASRResponse": {
      "type": "object",
      "properties": {
        "diathekeStreamAsrResponse": {
          "$ref": "#/definitions/diathekev3StreamASRResponse"
        }
      },
      "description": "The top-level message sent by the server for the `StreamASR` method."
    },
    "bluehengev1StreamTTSResponse": {
      "type": "object",
      "properties": {
        "diathekeStreamTtsResponse": {
          "$ref": "#/definitions/diathekev3StreamTTSResponse"
        }
      },
      "description": "The top-level message sent by the server for the `StreamTTS` method."
    },
    "bluehengev1TranscribeResponse": {
      "type": "object",
      "properties": {
        "diathekeTranscribeResponse": {
          "$ref": "#/definitions/diathekev3TranscribeResponse"
        }
      },
      "description": "The top-level message sent by the server for the `Transcribe` method."
    },
    "bluehengev1UpdateSessionResponse": {
      "type": "object",
      "properties": {
        "diathekeUpdateSessionResponse": {
          "$ref": "#/definitions/diathekev3UpdateSessionResponse"
        }
      },
      "description": "The top-level message sent by the server for the `UpdateSession` method."
    },
    "bluehengev1VersionResponse": {
      "type": "object",
      "properties": {
        "bluehenge": {
          "type": "string",
          "title": "Bluehenge engine"
        },
        "diathekeVersionResponse": {
          "$ref": "#/definitions/diathekev3VersionResponse",
          "title": "Diatheke Version Response"
        }
      },
      "description": "Lists the version of Diatheke and the engines it uses."
    },
    "diathekev3AudioEncoding": {
      "type": "string",
      "enum": [
        "AUDIO_ENCODING_UNSPECIFIED",
        "AUDIO_ENCODING_SIGNED",
        "AUDIO_ENCODING_UNSIGNED",
        "AUDIO_ENCODING_IEEE_FLOAT",
        "AUDIO_ENCODING_ULAW",
        "AUDIO_ENCODING_ALAW"
      ],
      "default": "AUDIO_ENCODING_UNSPECIFIED",
      "description": "The encoding of the audio data to be sent for synthesis.\n\n - AUDIO_ENCODING_UNSPECIFIED: AUDIO_ENCODING_UNSPECIFIED is the default value of this type and will\nresult in an error.\n - AUDIO_ENCODING_SIGNED: PCM signed-integer\n - AUDIO_ENCODING_UNSIGNED: PCM unsigned-integer\n - AUDIO_ENCODING_IEEE_FLOAT: PCM IEEE-Float\n - AUDIO_ENCODING_ULAW: G.711 mu-law\n - AUDIO_ENCODING_ALAW: G.711 a-law"
    },
    "diathekev3ByteOrder": {
      "type": "string",
      "enum": [
        "BYTE_ORDER_UNSPECIFIED",
        "BYTE_ORDER_LITTLE_ENDIAN",
        "BYTE_ORDER_BIG_ENDIAN"
      ],
      "default": "BYTE_ORDER_UNSPECIFIED",
      "description": "- BYTE_ORDER_UNSPECIFIED: BYTE_ORDER_UNSPECIFIED is the default value of this type.\n - BYTE_ORDER_LITTLE_ENDIAN: Little Endian byte order\n - BYTE_ORDER_BIG_ENDIAN: Big Endian byte order",
      "title": "Byte order of multi-byte data"
    },
    "diathekev3CreateSessionRequest": {
      "type": "object",
      "properties": {
        "modelId": {
          "type": "string",
          "description": "Specifies the Diatheke model ID to use for the session."
        },
        "wakeword": {
          "type": "string",
          "description": "Specifies a custom wakeword to use for this session. The\nwakeword must be enabled in the Diatheke model for this\nto have any effect. It will override the default wakeword\nspecified in the model."
        },
        "metadata": {
          "$ref": "#/definitions/v3SessionMetadata",
          "description": "This is an optional field to provide any metadata associated with the\nsession. The server may record this metadata when processing the\nrequest. The server does not use this field for any other purpose."
        },
        "inputAudioFormat": {
          "$ref": "#/definitions/v3AudioFormat",
          "description": "Format of the audio system expects to recieve. This is an optional\nfield, and if no value is specified, input will be assumed to be raw\nbytes (PCM16SLE) at the sample rate that speech processing models\nare configured to use on the server."
        },
        "outputAudioFormat": {
          "$ref": "#/definitions/v3AudioFormat",
          "description": "Format of the audio client expects to recieve. This is an optional\nfield. If no value is specified, the output will be produced with a\nnative audio format that text-to-speech models are configured on\nthe server."
        }
      },
      "description": "The top-level message sent by the client for the `CreateSession` method."
    },
    "diathekev3CreateSessionResponse": {
      "type": "object",
      "properties": {
        "sessionOutput": {
          "$ref": "#/definitions/v3SessionOutput"
        }
      },
      "description": "The top-level message sent by the server for the `CreateSession` method."
    },
    "diathekev3DeleteSessionRequest": {
      "type": "object",
      "properties": {
        "tokenData": {
          "$ref": "#/definitions/v3TokenData"
        }
      },
      "description": "The top-level message sent by the client for the `DeleteSession` method."
    },
    "diathekev3DeleteSessionResponse": {
      "type": "object",
      "description": "The top-level message sent by the server for the `DeleteSession` method."
    },
    "diathekev3ListModelsRequest": {
      "type": "object",
      "description": "The top-level message sent by the client for the `ListModels` method."
    },
    "diathekev3ListModelsResponse": {
      "type": "object",
      "properties": {
        "models": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/diathekev3ModelInfo"
          }
        }
      },
      "description": "A list of models available on the Diatheke server."
    },
    "diathekev3ModelInfo": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "description": "Diatheke model ID, which is used to create a new session."
        },
        "name": {
          "type": "string",
          "description": "Pretty model name, which may be used for display purposes."
        },
        "language": {
          "type": "string",
          "description": "Language code of the model."
        },
        "asrSampleRate": {
          "type": "integer",
          "format": "int64",
          "description": "The ASR audio sample rate, if ASR is enabled."
        },
        "ttsSampleRate": {
          "type": "integer",
          "format": "int64",
          "description": "The TTS audio sample rate, if TTS is enabled."
        }
      },
      "description": "Information about a single Diatheke model."
    },
    "diathekev3StreamASRRequest": {
      "type": "object",
      "properties": {
        "token": {
          "$ref": "#/definitions/v3TokenData",
          "description": "Session data, used to determine the correct Cubic\nmodel to use for ASR, with other contextual\ninformation."
        },
        "audio": {
          "type": "string",
          "format": "byte",
          "description": "Audio data to transcribe."
        }
      },
      "description": "Data to send to the ASR stream. The first message on the\nstream must be the session token followed by audio data."
    },
    "diathekev3StreamASRResponse": {
      "type": "object",
      "properties": {
        "asrResult": {
          "$ref": "#/definitions/v3ASRResult"
        }
      }
    },
    "diathekev3StreamTTSRequest": {
      "type": "object",
      "properties": {
        "replyAction": {
          "$ref": "#/definitions/v3ReplyAction",
          "description": "Reply action contains reply text and model ID."
        },
        "token": {
          "$ref": "#/definitions/v3TokenData",
          "description": "Token data to provide session ID and other contextual information."
        }
      },
      "description": "The top-level message sent by the client for the `StreamTTS` method."
    },
    "diathekev3StreamTTSResponse": {
      "type": "object",
      "properties": {
        "audio": {
          "type": "string",
          "format": "byte"
        }
      },
      "description": "The top-level message sent by the server for the `StreamTTS` method.\nContains synthesized speech audio. The specific encoding\nis defined in the server config file."
    },
    "diathekev3TranscribeRequest": {
      "type": "object",
      "properties": {
        "action": {
          "$ref": "#/definitions/v3TranscribeAction",
          "description": "Action defining the transcribe configuration."
        },
        "audio": {
          "type": "string",
          "format": "byte",
          "description": "Audio data to transcribe."
        }
      },
      "description": "Data to send to the Transcribe stream. The first message on\nthe stream must be a TranscribeAction, followed by audio data."
    },
    "diathekev3TranscribeResponse": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "description": "The transcription."
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "Confidence estimate between 0 and 1. A higher number\nrepresents a higher likelihood that the transcription\nis correct."
        },
        "isPartial": {
          "type": "boolean",
          "description": "True if this is a partial result, in which case the\nnext result will be for the same audio, either repeating\nor correcting the text in this result. When false, this\nrepresents the final transcription for an utterance, which\nwill not change with further audio input. It is sent when\nthe ASR has identified an endpoint. After the final\ntranscription is sent, any additional results sent on the\nTranscribe stream belong to the next utterance."
        },
        "cubicResult": {
          "$ref": "#/definitions/v5RecognitionResult",
          "description": "Cubic recognition result."
        }
      },
      "description": "The result from the Transcribe stream. Usually, several partial\n(or intermediate) transcriptions will be sent until the final\ntranscription is ready for every utterance processed."
    },
    "diathekev3UpdateSessionRequest": {
      "type": "object",
      "properties": {
        "sessionInput": {
          "$ref": "#/definitions/v3SessionInput"
        }
      },
      "description": "The top-level message sent by the client for the `UpdateSession` method."
    },
    "diathekev3UpdateSessionResponse": {
      "type": "object",
      "properties": {
        "sessionOutput": {
          "$ref": "#/definitions/v3SessionOutput"
        }
      },
      "description": "The top-level message sent by the server for the `UpdateSession` method."
    },
    "diathekev3VersionResponse": {
      "type": "object",
      "properties": {
        "diatheke": {
          "type": "string",
          "title": "Dialog management engine"
        },
        "chosun": {
          "type": "string",
          "title": "NLU engine"
        },
        "cubic": {
          "type": "string",
          "title": "ASR engine"
        },
        "luna": {
          "type": "string",
          "title": "TTS engine"
        }
      },
      "description": "Lists the version of Diatheke and the engines it uses."
    },
    "protobufAny": {
      "type": "object",
      "properties": {
        "@type": {
          "type": "string"
        }
      },
      "additionalProperties": {}
    },
    "rpcStatus": {
      "type": "object",
      "properties": {
        "code": {
          "type": "integer",
          "format": "int32"
        },
        "message": {
          "type": "string"
        },
        "details": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/protobufAny"
          }
        }
      }
    },
    "v1GetEntityImageResponse": {
      "type": "object",
      "properties": {
        "imageDataList": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v1ImageData"
          },
          "title": "List of images data"
        }
      },
      "title": "Output of get entity image"
    },
    "v1GetImageResponse": {
      "type": "object",
      "properties": {
        "fileChunk": {
          "type": "string",
          "format": "byte",
          "title": "Image given by chunks of bytes"
        }
      },
      "title": "Output of the image required"
    },
    "v1GetProceduresResponse": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "title": "Id of the procedure"
        },
        "name": {
          "type": "string",
          "title": "Name of the procedure"
        },
        "procedureNumber": {
          "type": "string",
          "title": "Number of the procedure"
        },
        "additionalNames": {
          "type": "string",
          "description": "This will be repeated",
          "title": "AdditionalNames of the task"
        },
        "inputConditions": {
          "type": "string",
          "description": "This will be inputConditions",
          "title": "InputConditions text of the procedure"
        },
        "prerequisitesWarningText": {
          "type": "string",
          "title": "Prerequisites of the procedure"
        },
        "tasks": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v1TaskData"
          },
          "title": "List of Task data of the procedure"
        }
      },
      "title": "Procedure from Gremlin"
    },
    "v1ImageData": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "title": "Id of an image"
        },
        "filePath": {
          "type": "string",
          "title": "File path of an image"
        },
        "caption": {
          "type": "string",
          "title": "Caption of an image"
        }
      },
      "title": "Data from an image"
    },
    "v1ListProceduresResponse": {
      "type": "object",
      "properties": {
        "procedures": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v1GetProceduresResponse"
          },
          "title": "Repeated (list) procedures from Gremlin/knowledge graph"
        }
      },
      "title": "List of procedures from Gremlin"
    },
    "v1Notes": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "title": "Text of the note"
        }
      },
      "title": "Notes of a step"
    },
    "v1SaveNoteResponse": {
      "type": "object",
      "title": "Empty response once the note is saved"
    },
    "v1StepData": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "title": "Id of the step"
        },
        "instructionText": {
          "type": "string",
          "title": "Instructions of the step"
        },
        "summaryText": {
          "type": "string",
          "title": "Summary of the step"
        },
        "person": {
          "type": "string",
          "title": "DisplayLabelText of the step"
        },
        "taskNumber": {
          "type": "string",
          "title": "TaskNumber of the step"
        },
        "stepNumber": {
          "type": "string",
          "title": "StepNumber of the step"
        },
        "image": {
          "type": "string",
          "title": "Image of the step"
        },
        "notes": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v1Notes"
          },
          "title": "List of notes of the step"
        }
      },
      "title": "Data of steps within a task"
    },
    "v1TaskData": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "title": "Id of the task"
        },
        "taskName": {
          "type": "string",
          "title": "TaskName of the task"
        },
        "taskNumber": {
          "type": "string",
          "title": "TaskNumber of the task"
        },
        "additionalNames": {
          "type": "string",
          "description": "This will be repeated",
          "title": "AdditionalNames of the task"
        },
        "warningText": {
          "type": "string",
          "title": "WarningText of the task"
        },
        "steps": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v1StepData"
          },
          "title": "List of steps of the task"
        }
      },
      "title": "Data of tasks within a procedure"
    },
    "v2Entity": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "description": "The name of the entity."
        },
        "value": {
          "type": "string",
          "description": "The value of the entity based on the input text. Depending on the\nChosun model, this might not be the same as what was given in\nthe input string, especially if a synonym replacement occurred.\nTo find the original value as it was given in the input, use the\nstart and end index of the entity."
        },
        "start": {
          "type": "integer",
          "format": "int64",
          "description": "The index in the original text string where the entity value begins."
        },
        "end": {
          "type": "integer",
          "format": "int64",
          "description": "The index in the original text string where the entity value ends.\nNote that this index will be one past the last character of the\nentity value."
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "confidence is the confidence value between 0 and 1 for the given entity."
        }
      },
      "description": "An entity recognized from the input text."
    },
    "v2Intent": {
      "type": "object",
      "properties": {
        "domain": {
          "type": "string",
          "description": "The domain recognized for the query. If a Chosun model was queried\ndirectly, this will be an empty string."
        },
        "id": {
          "type": "string",
          "description": "The name of the intent."
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "Confidence estimate between 0 and 1. A higher number\nrepresents a higher likelihood of the output being\ncorrect."
        },
        "entities": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v2Entity"
          },
          "description": "The list of entities recognized with this intent."
        },
        "text": {
          "type": "string",
          "description": "The text of the query. This is helpful when an n-best list is provided."
        }
      },
      "description": "An intent recognized from the input text."
    },
    "v2ParseResponse": {
      "type": "object",
      "properties": {
        "intents": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v2Intent"
          },
          "description": "The list of recognized intents, sorted by confidence."
        }
      },
      "description": "Data returned from the Parse method."
    },
    "v3ASRResult": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "description": "The transcription."
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "Confidence estimate between 0 and 1. A higher number\nrepresents a higher likelihood of the output being\ncorrect."
        },
        "timedOut": {
          "type": "boolean",
          "description": "True if a timeout was defined for the session's current\ninput state in the Diatheke model, and the timeout\nexpired before getting a transcription. This timeout\nrefers to the amount of time a user has to verbally\nrespond to Diatheke after the ASR stream has been\ncreated, and should not be confused with a network\nconnection timeout."
        },
        "cubicResult": {
          "$ref": "#/definitions/v5RecognitionResult",
          "description": "Cubic recognition result."
        }
      },
      "description": "The result from the ASR stream, sent after the ASR engine\nhas endpointed or the stream was closed by the client."
    },
    "v3ActionData": {
      "type": "object",
      "properties": {
        "input": {
          "$ref": "#/definitions/v3WaitForUserAction",
          "description": "The user must provide input to Diatheke."
        },
        "command": {
          "$ref": "#/definitions/v3CommandAction",
          "description": "The client app must execute the specified command."
        },
        "reply": {
          "$ref": "#/definitions/v3ReplyAction",
          "description": "The client app should provide the reply to the user."
        },
        "transcribe": {
          "$ref": "#/definitions/v3TranscribeAction",
          "description": "The client app should call the Transcribe method to\ncapture the user's input."
        }
      },
      "description": "Specifies an action that the client application should take."
    },
    "v3AudioCodec": {
      "type": "string",
      "enum": [
        "AUDIO_CODEC_UNSPECIFIED",
        "AUDIO_CODEC_RAW",
        "AUDIO_CODEC_WAV",
        "AUDIO_CODEC_MP3",
        "AUDIO_CODEC_FLAC",
        "AUDIO_CODEC_OGG_OPUS"
      ],
      "default": "AUDIO_CODEC_UNSPECIFIED",
      "description": "The encoding of the audio data to be sent for synthesis.\n\n - AUDIO_CODEC_UNSPECIFIED: AUDIO_CODEC_UNSPECIFIED is the default value of this type.\n - AUDIO_CODEC_RAW: Raw data without any headers\n - AUDIO_CODEC_WAV: WAV with RIFF headers\n - AUDIO_CODEC_MP3: MP3 format with a valid frame header at the beginning of data\n - AUDIO_CODEC_FLAC: FLAC format\n - AUDIO_CODEC_OGG_OPUS: Opus format with OGG header"
    },
    "v3AudioFormat": {
      "type": "object",
      "properties": {
        "sampleRate": {
          "type": "integer",
          "format": "int64",
          "description": "Sampling rate in Hz."
        },
        "channels": {
          "type": "integer",
          "format": "int64",
          "description": "Number of channels present in the audio. E.g.: 1 (mono), 2 (stereo), etc."
        },
        "bitDepth": {
          "type": "integer",
          "format": "int64",
          "description": "Bit depth of each sample (e.g. 8, 16, 24, 32, etc.)."
        },
        "codec": {
          "$ref": "#/definitions/v3AudioCodec",
          "description": "Codec of the samples."
        },
        "encoding": {
          "$ref": "#/definitions/diathekev3AudioEncoding",
          "description": "Encoding of the samples."
        },
        "byteOrder": {
          "$ref": "#/definitions/diathekev3ByteOrder",
          "description": "Byte order of the samples. This field must be set to a value other than\n`BYTE_ORDER_UNSPECIFIED` when the `bit_depth` is greater than 8."
        }
      },
      "title": "Details of audio in format"
    },
    "v3CommandAction": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "description": "The ID of the command to execute, as defined in the\nDiatheke model."
        },
        "inputParameters": {
          "type": "object",
          "additionalProperties": {
            "type": "string"
          }
        },
        "nluResult": {
          "$ref": "#/definitions/v2ParseResponse",
          "title": "NLU result"
        }
      },
      "description": "This action indicates that the client application should\nexecute a command."
    },
    "v3CommandResult": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "title": "The command ID, as given by the CommandAction"
        },
        "outParameters": {
          "type": "object",
          "additionalProperties": {
            "type": "string"
          },
          "description": "Output from the command expected by the Diatheke model.\nFor example, this could be the result of a data query."
        },
        "error": {
          "type": "string",
          "description": "If there was an error during execution, indicate it\nhere with a brief message that will be logged by\nDiatheke."
        }
      },
      "description": "The result of executing a command."
    },
    "v3ReplyAction": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "title": "Text of the reply"
        },
        "lunaModel": {
          "type": "string",
          "title": "TTS model to use with the TTSReply method"
        }
      },
      "description": "This action indicates that the client application should\ngive the provided text to the user. This action may also\nbe used to synthesize speech with the StreamTTS method."
    },
    "v3SessionInput": {
      "type": "object",
      "properties": {
        "token": {
          "$ref": "#/definitions/v3TokenData",
          "description": "The session token."
        },
        "text": {
          "$ref": "#/definitions/v3TextInput",
          "description": "Process the user supplied text."
        },
        "asr": {
          "$ref": "#/definitions/v3ASRResult",
          "description": "Process an ASR result."
        },
        "cmd": {
          "$ref": "#/definitions/v3CommandResult",
          "description": "Process the result of a completed command."
        },
        "story": {
          "$ref": "#/definitions/v3SetStory",
          "description": "Change the current session state."
        }
      },
      "description": "Used by Diatheke to update the session state."
    },
    "v3SessionMetadata": {
      "type": "object",
      "properties": {
        "customMetadata": {
          "type": "string",
          "description": "Any custom metadata that the client wants to associate with the session.\nThis could be a simple string (e.g. a tracing ID) or structured data\n(e.g. JSON)."
        },
        "storageFilePrefix": {
          "type": "string",
          "description": "This is an optional field to specify prefix of files that will be\nsaved for this session."
        }
      },
      "description": "Metadata associated with the session."
    },
    "v3SessionOutput": {
      "type": "object",
      "properties": {
        "token": {
          "$ref": "#/definitions/v3TokenData",
          "description": "The updated session token."
        },
        "actionList": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v3ActionData"
          },
          "description": "The list of actions the client should take next,\nusing the session token returned with this result."
        }
      },
      "description": "The result of updating a session."
    },
    "v3SetStory": {
      "type": "object",
      "properties": {
        "storyId": {
          "type": "string",
          "description": "The ID of the story to run, as defined in the\nDiatheke model."
        },
        "parameters": {
          "type": "object",
          "additionalProperties": {
            "type": "string"
          },
          "description": "A list of parameters to set before running the given\nstory. This will replace any parameters currently\ndefined in the session."
        }
      },
      "description": "Changes the current state of a Diatheke session to run at\nthe specified story."
    },
    "v3TextInput": {
      "type": "object",
      "properties": {
        "text": {
          "type": "string"
        }
      },
      "description": "User supplied text to send to Diatheke for processing."
    },
    "v3TokenData": {
      "type": "object",
      "properties": {
        "data": {
          "type": "string",
          "format": "byte"
        },
        "id": {
          "type": "string",
          "description": "Session ID, useful for correlating logging between a\nclient and the server."
        },
        "metadata": {
          "type": "string",
          "description": "Additional data supplied by the client app, which will\nbe logged with other session info by the server."
        }
      },
      "description": "A token that represents a single Diatheke session and its\ncurrent state."
    },
    "v3TranscribeAction": {
      "type": "object",
      "properties": {
        "id": {
          "type": "string",
          "description": "The ID of the transcribe action, which is useful to\ndifferentiate separate transcription tasks within a\nsingle sesssion."
        },
        "cubicModelId": {
          "type": "string",
          "description": "(Required) The ASR model to use for transcription."
        },
        "diathekeModelId": {
          "type": "string",
          "description": "(Optional) A Diatheke model to use for end-of-stream\nconditions. If empty, the server will not be able to\nautomatically close the transcribe stream based on\nconditions defined in the model, such as\na non-speech timeout or an \"end-transcription\" intent.\nWhen empty, the stream must be closed by the client\napplication."
        }
      },
      "description": "This action indicates that the client application should\ncall the Transcribe method to capture the user's input."
    },
    "v3WaitForUserAction": {
      "type": "object",
      "properties": {
        "requiresWakeWord": {
          "type": "boolean",
          "description": "True if the next user input must begin with a wake-word."
        },
        "immediate": {
          "type": "boolean",
          "description": "True if the input is required immediately (i.e., in\nresponse to a question Diatheke asked the user). When\nfalse, the client should be allowed to wait indefinitely\nfor the user to provide input."
        }
      },
      "description": "This action indicates that Diatheke is expecting user input."
    },
    "v5ConfusionNetworkArc": {
      "type": "object",
      "properties": {
        "word": {
          "type": "string",
          "title": "Word in the recognized transcript"
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "Confidence estimate between 0 and 1. A higher number represents a higher\nlikelihood that the word was correctly recognized."
        },
        "features": {
          "$ref": "#/definitions/v5ConfusionNetworkArcFeatures",
          "title": "Features related to this arc"
        }
      },
      "title": "An Arc inside a Confusion Network Link"
    },
    "v5ConfusionNetworkArcFeatures": {
      "type": "object",
      "properties": {
        "confidence": {
          "type": "object",
          "additionalProperties": {
            "type": "number",
            "format": "double"
          },
          "title": "A map of features that are used for recalculating confidence scores of this\nconfusion network arc"
        }
      },
      "title": "Features related to confusion network arcs"
    },
    "v5ConfusionNetworkLink": {
      "type": "object",
      "properties": {
        "startTimeMs": {
          "type": "string",
          "format": "uint64",
          "title": "Time offset in milliseconds relative to the beginning of audio received by\nthe recognizer and corresponding to the start of this link"
        },
        "durationMs": {
          "type": "string",
          "format": "uint64",
          "title": "Duration in milliseconds of the current link in the confusion network"
        },
        "arcs": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v5ConfusionNetworkArc"
          },
          "title": "Arcs between this link"
        }
      },
      "title": "A Link inside a confusion network"
    },
    "v5RecognitionAlternative": {
      "type": "object",
      "properties": {
        "transcriptFormatted": {
          "type": "string",
          "description": "Text representing the transcription of the words that the user spoke.\n\nThe transcript will be formatted according to the servers formatting\nconfiguration. If you want the raw transcript, please see the field\n`transcript_raw`. If the server is configured to not use any formatting,\nthen this field will contain the raw transcript.\n\nAs an example, if the spoken utterance was \"four people\", and the server\nwas configured to format numbers, this field would be set to \"4 people\"."
        },
        "transcriptRaw": {
          "type": "string",
          "description": "Text representing the transcription of the words that the user spoke,\nwithout any formatting applied. If you want the formatted transcript,\nplease see the field `transcript_formatted`.\n\nAs an example, if the spoken utterance was `four people`, this field would\nbe set to \"FOUR PEOPLE\"."
        },
        "startTimeMs": {
          "type": "string",
          "format": "uint64",
          "description": "Time offset in milliseconds relative to the beginning of audio received by\nthe recognizer and corresponding to the start of this utterance."
        },
        "durationMs": {
          "type": "string",
          "format": "uint64",
          "description": "Duration in milliseconds of the current utterance in the spoken audio."
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "Confidence estimate between 0 and 1. A higher number represents a higher\nlikelihood of the output being correct."
        },
        "wordDetails": {
          "$ref": "#/definitions/v5WordDetails",
          "description": "Word-level details corresponding to the transcripts. This is available only\nif `enable_word_details` was set to `true` in the `RecognitionConfig`."
        }
      },
      "title": "A recognition hypothesis"
    },
    "v5RecognitionConfusionNetwork": {
      "type": "object",
      "properties": {
        "links": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v5ConfusionNetworkLink"
          }
        }
      },
      "title": "Confusion network in recognition output"
    },
    "v5RecognitionResult": {
      "type": "object",
      "properties": {
        "alternatives": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v5RecognitionAlternative"
          },
          "title": "An n-best list of recognition hypotheses alternatives"
        },
        "isPartial": {
          "type": "boolean",
          "description": "If this is set to true, it denotes that the result is an interim partial\nresult, and could change after more audio is processed. If unset, or set to\nfalse, it denotes that this is a final result and will not change.\n\nServers are not required to implement support for returning partial\nresults, and clients should generally not depend on their availability."
        },
        "cnet": {
          "$ref": "#/definitions/v5RecognitionConfusionNetwork",
          "description": "If `enable_confusion_network` was set to true in the `RecognitionConfig`,\nand if the model supports it, a confusion network will be available in the\nresults."
        },
        "audioChannel": {
          "type": "integer",
          "format": "int64",
          "description": "Channel of the audio file that this result was transcribed from. Channels\nare 0-indexed, so the for mono audio data, this value will always be 0."
        }
      },
      "description": "A recognition result corresponding to a portion of audio."
    },
    "v5WordDetails": {
      "type": "object",
      "properties": {
        "formatted": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v5WordInfo"
          },
          "description": "Word-level information corresponding to the `transcript_formatted` field."
        },
        "raw": {
          "type": "array",
          "items": {
            "type": "object",
            "$ref": "#/definitions/v5WordInfo"
          },
          "description": "Word-level information corresponding to the `transcript_raw` field."
        }
      }
    },
    "v5WordInfo": {
      "type": "object",
      "properties": {
        "word": {
          "type": "string",
          "title": "The actual word in the text"
        },
        "confidence": {
          "type": "number",
          "format": "double",
          "description": "Confidence estimate between 0 and 1. A higher number represents a higher\nlikelihood that the word was correctly recognized."
        },
        "startTimeMs": {
          "type": "string",
          "format": "uint64",
          "description": "Time offset in milliseconds relative to the beginning of audio received by\nthe recognizer and corresponding to the start of this spoken word."
        },
        "durationMs": {
          "type": "string",
          "format": "uint64",
          "description": "Duration in milliseconds of the current word in the spoken audio."
        }
      },
      "title": "Word level details for recognized words in a transcript"
    }
  }
}
